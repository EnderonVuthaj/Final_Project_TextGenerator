# Final_Project_TextGenerator

## Checkpoint 1

Challenges Faced:

-> Determining appropriate dimensions for each layer.

-> Determining the vocabulary size accurately.

-> Integrating tokenization correctly, so it works correcrtly within the Nengo model.


Adjustments Made:


-> Assumed dimensions and vocabulary size and loss functions will be optimal for training the system.

-> Handled tokenization separately using external libraries.

-> Made assumptions on the number of optimal layers.


Path Forward:

-> Experiment with different dimensions and vocabulary sizes and hyperparameters for optimal performance.

-> Work on Nengo model early on, so I can get help if needed.

-> Continue refining the model iteratively based on performance feedback.
